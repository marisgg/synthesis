{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from config import *\n",
    "import operator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"lualatex\"\n",
    "# })\n",
    "font_scale = 1.5\n",
    "sns.set_theme(style=\"whitegrid\",font_scale=font_scale)\n",
    "fontsize = 15\n",
    "plt.rc(\"font\", **{\"family\": \"serif\", \"serif\": [\"Times\"], \"size\" : fontsize})\n",
    "plt.rc(\"text\", usetex=True)\n",
    "save_format = 'pdf'\n",
    "backend = 'pdf'\n",
    "transparent = True\n",
    "pad_inches = 0.1\n",
    "bbox_inches = 'tight'\n",
    "save_args = {\n",
    "    'format' : save_format,\n",
    "    'backend' : backend,\n",
    "    'transparent' : transparent,\n",
    "    'pad_inches' : pad_inches,\n",
    "    'bbox_inches' : bbox_inches,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR='./outputs/second'\n",
    "# BASE_DIR='./output-union'\n",
    "# BASE_DIR='./bert/output-merged'\n",
    "# BASE_DIR='./output-parallel-subfamily'\n",
    "# BASE_DIR='./output-parallel-bert'\n",
    "# BASE_DIR='./verifai/output/parallel-full'\n",
    "BASE_DIR='./verifaiIJCAI/outputIJCAI/parallel-IJCAI'\n",
    "SUBFAMILY_SIZE=10\n",
    "SEED=2\n",
    "SEEDS=list(range(2,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./statistics.pickle\", 'rb') as handle:\n",
    "    statistics = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics[ENVS[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"./plot_builder_output-clean\"\n",
    "os.makedirs(f\"{OUTPUT_DIR}/heatmaps\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/lineplot\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def make_heatmap(results : dict, our_results : dict, title : str, baseline : str, union_results : dict = None, minimizing = True, add_whole_family_value = True):\n",
    "    # print([np.atleast_1d(list(item[-2].values())) for train, item in results.items()])\n",
    "    print(np.ravel(list(results[6][-2].values())).shape)\n",
    "    print(np.ravel(list(results[7][-2].values())).shape)\n",
    "    print(np.ravel(list(results[8][-2].values())).shape)\n",
    "    values = np.array([np.ravel(list(item[-2].values())) for train, item in results.items()])#.squeeze(axis=-1)\n",
    "    values[~np.isfinite(values)] = np.nan\n",
    "    # if add_whole_family_value:\n",
    "        # entire_family_values = np.array([item[-1] for train, item in results.items()])\n",
    "        # values = np.hstack([values, entire_family_values[..., None]])\n",
    "    if union_results:\n",
    "        # print(values, union_results['subfamily'])\n",
    "        # print(np.shape(values), np.shape()\n",
    "        if type(union_results['subfamily']) == dict:\n",
    "            ur = list(union_results['subfamily'].values())\n",
    "        else:\n",
    "            ur = union_results['subfamily']\n",
    "            \n",
    "        values = np.vstack([values, ur])\n",
    "    values = np.vstack([values, our_results['ours']])\n",
    "    if add_whole_family_value:\n",
    "        entire_family_values = np.array([item[-1] if item[-1] is not None else np.nan for train, item in results.items()] + ([union_results['whole_family']] if union_results else []) + [our_results['whole_family']])\n",
    "        # entire_family_values[~np.isfinite(entire_family_values)] = np.nan\n",
    "        values = np.hstack([values, entire_family_values[..., None]])\n",
    "    plt.figure(figsize=(16,9))\n",
    "    \n",
    "    if minimizing:\n",
    "        colormap = sns.cm.rocket_r\n",
    "        # colormap.set_bad(sns.cm.rocket.get_bad())\n",
    "    else:\n",
    "        colormap = sns.cm.rocket\n",
    "    # colormap.set_bad('black')\n",
    "    \n",
    "    \n",
    "    ax = sns.heatmap(values, annot=True, vmin=np.nanmin(values), vmax=np.nanmax(values), cmap=colormap, fmt='.2f')#, mask=~np.isfinite(values))\n",
    "    \n",
    "    # if add_whole_family_value:\n",
    "        # ax.add_patch(Rectangle((0,0), 10, 11, fill=False, edgecolor='white', lw=3)) # White bounding box\n",
    "    \n",
    "    subfamily_size = len(results.keys())\n",
    "    \n",
    "    best_value = np.inf if minimizing else -np.inf\n",
    "    for r in range(values.shape[0]):\n",
    "        row_values = values[r][:-1] if add_whole_family_value else values[r]\n",
    "        if np.isfinite(row_values).any():\n",
    "            idx = np.nanargmax(row_values) if minimizing else np.nanargmin(row_values)\n",
    "        else:\n",
    "            idx = random.randint(0, len(row_values)-1)\n",
    "        cmp = operator.le if minimizing else operator.ge\n",
    "        if cmp(row_values[idx], best_value):\n",
    "            best_value = row_values[idx]\n",
    "            best_rectangle = (idx, r)\n",
    "        ax.add_patch(Rectangle((idx, r),1,1, fill=False, edgecolor='blue', lw=3))\n",
    "    ax.add_patch(Rectangle(best_rectangle,1,1, fill=False, edgecolor='green', lw=3))\n",
    "    \n",
    "    if add_whole_family_value:\n",
    "        best_family_idx = np.nanargmin(values[:, -1]) if minimizing else np.nanargmax(values[:, -1])\n",
    "        ax.add_patch(Rectangle((subfamily_size, best_family_idx),1,1, fill=False, edgecolor='green', lw=3))\n",
    "    \n",
    "    ax.set_xlabel(\"Test\")\n",
    "    ax.set_ylabel(\"Train\")\n",
    "    plt.yticks(rotation=0) \n",
    "    xticks = [f\"{i}\" for i in range(subfamily_size)]\n",
    "    if add_whole_family_value:\n",
    "        xticks += [\"Entire family\"]\n",
    "    ax.set_xticklabels(xticks) \n",
    "    ax.set_yticklabels([f\"{baseline} on {i} ({results[i][1].num_nodes if results[i][1] else None}-FSC)\" for i in range(subfamily_size)] + ([\"Saynt on Union\"] if union_results else []) + [\"Ours: GD on (sub)family\"])\n",
    "    ax.set_title(f\"{title}: {baseline} vs Ours ({'lower' if minimizing else 'higher'} is better)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/heatmaps/{title}-{baseline}.{save_format}\", **save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def make_lineplot(results : dict, title : str = 'Placeholder', minimizing = True, type_of_plot = 'family_trace', use_time_x_axis=False):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    plt.title(f\"{title} ({'lower' if minimizing else 'higher'} is better)\")\n",
    "    plt.ylabel(\"Worst family member value\")\n",
    "    \n",
    "    max_time_normal = max(results['gd-normal']['plot_times'])\n",
    "    max_time_random = max(results['gd-random']['plot_times'])\n",
    "    \n",
    "    results['gd-random']['plot_times'] = (np.array(results['gd-random']['plot_times']) / max_time_random) * max_time_normal\n",
    "    \n",
    "    print(max_time_normal, max_time_random)\n",
    "    \n",
    "    if use_time_x_axis:\n",
    "        plt.xlabel(\"Time\")\n",
    "        print(results['gd-normal']['plot_times'])\n",
    "        ax.plot(results['gd-normal']['plot_times'], results['gd-normal'][type_of_plot], label='rfPG', color='green')\n",
    "    else:\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        ax.plot(results['gd-normal'][type_of_plot], label='rfPG', color='green')\n",
    "    \n",
    "    min_x_normal = np.argmin(results['gd-normal'][type_of_plot]) if minimizing else np.argmax(results['gd-normal'][type_of_plot])\n",
    "    min_y_normal = results['gd-normal'][type_of_plot][min_x_normal]\n",
    "    if use_time_x_axis: min_x_normal = results['gd-normal']['plot_times'][min_x_normal]\n",
    "    \n",
    "    # plt.plot(results['gd-no-momentum'][type_of_plot], label='rfPG (no momentum)', color='blue')\n",
    "    \n",
    "    # min_x_no_mom = np.argmin(results['gd-no-momentum'][type_of_plot]) if minimizing else np.argmax(results['gd-no-momentum'][type_of_plot])\n",
    "    # min_y_no_mom = results['gd-no-momentum'][type_of_plot][min_x_no_mom]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if use_time_x_axis:\n",
    "        ax.plot(results['gd-random']['plot_times'], results['gd-random'][type_of_plot], label='Random rfPG', color='red')\n",
    "    else:\n",
    "        exit()\n",
    "        ax.plot(results['gd-random'][type_of_plot], label='Random rfPG', color='red')\n",
    "\n",
    "    min_x = np.argmin(results['gd-random'][type_of_plot]) if minimizing else np.argmax(results['gd-random'][type_of_plot])\n",
    "    min_y = results['gd-random'][type_of_plot][min_x]\n",
    "    if use_time_x_axis: min_x = results['gd-random']['plot_times'][min_x]\n",
    "    \n",
    "    mini = min([min_x, min_x_normal])\n",
    "    maxi = max([min_x, min_x_normal])\n",
    "    \n",
    "    def get(x):\n",
    "        if math.isclose(mini, maxi) and math.isclose(x, maxi):\n",
    "            return random.randint(-50, 50)\n",
    "        elif math.isclose(x, maxi):\n",
    "            return 50\n",
    "        elif math.isclose(x, mini):\n",
    "            return -50\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    ax.annotate(f\"{min_y:.2f}\",\n",
    "            xy=(min_x, min_y), xycoords='data',\n",
    "            xytext=(get(min_x), (50 if minimizing else -50)), textcoords='offset points',\n",
    "            arrowprops=dict(facecolor='red', shrink=0),\n",
    "            horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    ax.annotate(f\"{min_y_normal:.2f}\",\n",
    "                xy=(min_x_normal, min_y_normal), xycoords='data',\n",
    "                xytext=(get(min_x_normal), (50 if minimizing else -50)), textcoords='offset points',\n",
    "                arrowprops=dict(facecolor='green', shrink=0),\n",
    "                horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    # ax.annotate(f\"{min_y_no_mom:.2f}\",\n",
    "    #     xy=(min_x_no_mom, min_y_no_mom), xycoords='data',\n",
    "    #     xytext=(get(min_x_no_mom), (50 if minimizing else -50)), textcoords='offset points',\n",
    "    #     arrowprops=dict(facecolor='blue', shrink=0),\n",
    "    #     horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/lineplot/{title}.{save_format}\", **save_args)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAMES = ['dpm', 'obstacles-10-2', 'avoid', 'obstacles-8-3', 'rover', 'network']\n",
    "MINIMIZING = [False, True, True, True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve_single_seed(envs=ENV_NAMES, minimizings=MINIMIZING, seed=SEED):\n",
    "    for env, minimizing in zip(envs, minimizings):\n",
    "        try:\n",
    "            with open(f\"{BASE_DIR}/{env}/{seed}/gd-experiment.pickle\", 'rb') as handle:\n",
    "                results = pickle.load(handle)\n",
    "                make_lineplot(results, title=env, minimizing=minimizing, use_time_x_axis=True)\n",
    "        except FileNotFoundError as fnfe:\n",
    "            print(fnfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def plot_learning_curve(envs=ENV_NAMES, minimizings=MINIMIZING, seed=SEED, use_ci=True):\n",
    "    \n",
    "    x_common = np.linspace(0, 100, 1000)\n",
    "    \n",
    "    for env, minimizing in zip(envs, minimizings):\n",
    "        rand_X = []\n",
    "        rand_Y = []\n",
    "        X = []\n",
    "        Y = []\n",
    "        for seed in SEEDS:\n",
    "            try:\n",
    "                with open(f\"{BASE_DIR}/{env}/seed{seed}/gd-experiment.pickle\", 'rb') as handle:\n",
    "                    results = pickle.load(handle)\n",
    "                    # make_lineplot(results, title=env, minimizing=minimizing, use_time_x_axis=True)\n",
    "            except FileNotFoundError as fnfe:\n",
    "                print(fnfe)\n",
    "                continue\n",
    "            \n",
    "            # print(env, seed)\n",
    "            \n",
    "            \n",
    "            type_of_plot = 'family_trace'                    \n",
    "            \n",
    "            x_random = np.array(results['gd-random']['plot_times']) \n",
    "            y_random = np.array(results['gd-random'][type_of_plot])\n",
    "            \n",
    "            rand_X.append(x_random)\n",
    "            rand_Y.append(y_random)\n",
    "\n",
    "            x = np.array(results['gd-normal']['plot_times'])\n",
    "            y = np.array(results['gd-normal'][type_of_plot])\n",
    "            \n",
    "            # if True:\n",
    "            try:\n",
    "                max_time_normal = max(results['gd-normal']['plot_times'])\n",
    "                max_time_random = max(results['gd-random']['plot_times'])\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if max_time_random >= max_time_normal:\n",
    "                x_random = (x_random / max_time_random) * max_time_normal\n",
    "            else:\n",
    "                x = (x / max_time_random) * max_time_normal\n",
    "            \n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            \n",
    "            # y_common = np.interp(x_common, this_x, this_y)\n",
    "            \n",
    "            # print(max_time_normal, max_time_random)\n",
    "        \n",
    "        num_points = 3600\n",
    "        x_common = np.linspace(0, 3600, num_points)\n",
    "\n",
    "        \n",
    "        def plot_interp(X, Y):\n",
    "            # y_sum = np.zeros(num_points)\n",
    "            y_agg = []\n",
    "            \n",
    "            assert len(rand_X) == len(rand_Y)\n",
    "            number_of_curves = len(rand_X)\n",
    "\n",
    "            for this_x, this_y in zip(X, Y):                \n",
    "                # Interpolate y so that it's using a common x-axis\n",
    "                try:\n",
    "                    y_common = np.interp(x_common, this_x, this_y)\n",
    "                except Exception as e:\n",
    "                    # print(this_x, this_y)\n",
    "                    continue\n",
    "                \n",
    "                # Add it to the other curves\n",
    "                y_agg += [y_common]\n",
    "\n",
    "            # Divide the sum by the number of curves to get the average curve\n",
    "            # y_average = y_sum / number_of_curves\n",
    "            \n",
    "            return y_agg\n",
    "            \n",
    "        # fig = plt.figure(figsize=(3,4))\n",
    "        # fig = plt.figure(figsize=(1.755 * 2,1.31 * 2))\n",
    "        plt.figure()\n",
    "        # ax = fig.gca()\n",
    "        rand_Y_interp = plot_interp(rand_X, rand_Y)\n",
    "        # sns.lineplot(x=rand_X_interp, y=rand_Y_interp, label='Random rfPG', color='red')\n",
    "        plt.plot(x_common, np.mean(rand_Y_interp, axis=0), label='Random', color='red')\n",
    "        \n",
    "        if use_ci:\n",
    "            ci_a, ci_b = scipy.stats.t.interval(0.95, len(x_common)-1, loc=np.mean(rand_Y_interp, axis=0), scale=scipy.stats.sem(rand_Y_interp, axis=0))\n",
    "            plt.fill_between(x_common, ci_a, ci_b,  alpha=0.25, color='red')\n",
    "        else:\n",
    "            plt.fill_between(x_common, np.mean(rand_Y_interp, axis=0) + np.var(rand_Y_interp, axis=0), np.mean(rand_Y_interp, axis=0) - np.var(rand_Y_interp, axis=0),  alpha=0.25, color='red')\n",
    "        \n",
    "        Y_interp = plot_interp(X, Y)\n",
    "        plt.plot(x_common, np.mean(Y_interp, axis=0), label=r'\\textsc{rfPG}', color='green')\n",
    "\n",
    "        if use_ci:\n",
    "            ci_a, ci_b = scipy.stats.t.interval(0.95, len(x_common)-1, loc=np.mean(Y_interp, axis=0), scale=scipy.stats.sem(Y_interp, axis=0))\n",
    "            plt.fill_between(x_common, ci_a, ci_b,  alpha=0.25, color='green')\n",
    "        else:\n",
    "            plt.fill_between(x_common, np.mean(Y_interp, axis=0) + np.std(Y_interp, axis=0), np.mean(Y_interp, axis=0) - np.std(Y_interp, axis=0),  alpha=0.25, color='green')\n",
    "        plt.title(f\"{env.upper()} ({'lower' if minimizing else 'higher'} is better)\")\n",
    "        plt.ylabel(\"Robust performance\")\n",
    "        plt.xlabel(\"Time (seconds)\")\n",
    "        # if 'obstacles-10-2' in env.lower():\n",
    "            # plt.ylim((20, 50))\n",
    "        # elif 'avoid' in env.lower():\n",
    "            # plt.ylim((5, 1000))\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f\"{OUTPUT_DIR}/lineplot\", exist_ok=True)\n",
    "        plt.savefig(f\"{OUTPUT_DIR}/lineplot/{env}.{save_format}\", **save_args)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFAULT FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(env : str, include_union_results : bool = True, seed=SEED, subfamsize=SUBFAMILY_SIZE, include_gd_results=False):\n",
    "    with open(f\"{BASE_DIR}/{env}/subfamsize{subfamsize}/seed{seed}/subfam-saynt.pickle\", 'rb') as handle:\n",
    "        saynt = pickle.load(handle)\n",
    "        \n",
    "    with open(f\"{BASE_DIR}/{env}/subfamsize{subfamsize}/seed{seed}/subfam-ours.pickle\", 'rb') as handle:\n",
    "        ours = pickle.load(handle)\n",
    "    \n",
    "    if include_gd_results:\n",
    "        with open(f\"{BASE_DIR}/{env}/subfamsize{subfamsize}/seed{seed}/subfam-gradient.pickle\", 'rb') as handle:\n",
    "            gradient = pickle.load(handle)\n",
    "    else:\n",
    "        gradient = None\n",
    "    \n",
    "    if include_union_results:\n",
    "        try:\n",
    "            with open(f\"{BASE_DIR}/{env}/union/seed{seed}/union.pickle\", 'rb') as handle: \n",
    "                union_results = pickle.load(handle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            union_results = None\n",
    "    else:\n",
    "        union_results = None\n",
    "    \n",
    "    if include_gd_results:\n",
    "        return saynt, ours, union_results, gradient\n",
    "    else:\n",
    "        return saynt, ours, union_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(envs : list[str], minimizings : list[bool], include_union_results = True):\n",
    "    subfamresults = {}\n",
    "    whlfamresults = {}\n",
    "    for env, minimizing in sorted(zip(envs, minimizings), key=lambda x : x[1]):\n",
    "        saynt, ours, union_results, gradient = load_results(env, include_union_results=include_union_results, include_gd_results=True)\n",
    "        \n",
    "        aggregator = lambda x : float((max if minimizing else min)(x))        \n",
    "        \n",
    "        env_id = f\"{env.upper()} ({'min.' if minimizing else 'max.'})\"\n",
    "        \n",
    "        \n",
    "        subfamresults[env_id] = {\n",
    "            # min if minimizing because taking the best FSC out of the 10 FSCs, but worst value for that FSC among the 10 POMDPs evaluated. \n",
    "            '\\\\saynt (one-by-one)' : (min if minimizing else max)([aggregator(np.array(list(saynt[k][2].values())).flatten().tolist()) for k in saynt.keys()]),\n",
    "            '\\\\saynt (union)' : aggregator(union_results['subfamily']) if union_results else np.nan,\n",
    "            '\\\\ours  (subfamily)'  : aggregator(ours['ours']),\n",
    "        }\n",
    "        \n",
    "        with open(f\"{BASE_DIR}/{env}/seed{SEED}/gd-experiment.pickle\", 'rb') as handle:\n",
    "            rfpg_results = pickle.load(handle)\n",
    "            \n",
    "        \n",
    "        \n",
    "        whlfamresults[env_id] = {\n",
    "            '\\\\saynt (one-by-one)' : aggregator([item[-1] if item[-1] is not None else np.nan for train, item in saynt.items()]),\n",
    "            '\\\\saynt (union)' : float(union_results['whole_family']) if union_results else np.nan,\n",
    "            '\\\\ours  (subfamily)'  : float(ours['whole_family']),\n",
    "            '\\\\ours  (whole family)' : rfpg_results['gd-normal']['best_worst_value']\n",
    "        }\n",
    "    \n",
    "    return subfamresults, whlfamresults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def create_table_multiple_seeds(envs : list[str], minimizings : list[bool], include_union_results = True, include_gd_results = True):\n",
    "    subfamresults = defaultdict(dict)\n",
    "    whlfamresults = defaultdict(dict)\n",
    "    for env, minimizing in sorted(zip(envs, minimizings), key=lambda x : x[1]):\n",
    "        \n",
    "        aggregator = lambda x : float((max if minimizing else min)(x))        \n",
    "        \n",
    "        env_id = f\"{env.upper()} ({'min.' if minimizing else 'max.'})\"\n",
    "        \n",
    "        subfamresults[env_id] = defaultdict(list)\n",
    "        whlfamresults[env_id] = defaultdict(list)\n",
    "        \n",
    "        # nan_num = np.inf if minimizing \n",
    "        \n",
    "        def hotfix(x : np.ndarray) -> np.ndarray:\n",
    "            \n",
    "            return x[~np.isnan(x)]\n",
    "\n",
    "        count = 0\n",
    "        \n",
    "        for seed in SEEDS:\n",
    "            try:\n",
    "                # saynt, ours, union_results = load_results(env, include_union_results=include_union_results, seed=seed)\n",
    "                saynt, ours, union_results, gradient = load_results(env, include_union_results=include_union_results, seed=seed, include_gd_results=include_gd_results)\n",
    "                \n",
    "                with open(f\"{BASE_DIR}/{env}/seed{seed}/gd-experiment.pickle\", 'rb') as handle:\n",
    "                    rfpg_results = pickle.load(handle)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "            # subfamresults[env_id] = {\n",
    "                # min if minimizing because taking the best FSC out of the 10 FSCs, but worst value for that FSC among the 10 POMDPs evaluated. \n",
    "                # '\\\\saynt (one-by-one)' : (min if minimizing else max)([aggregator(np.array(list(saynt[k][2].values())).flatten().tolist()) for k in saynt.keys()]),\n",
    "                # '\\\\saynt (union)' : aggregator(union_results['subfamily']) if union_results else np.nan,\n",
    "                # '\\\\ours  (subfamily)' : aggregator(ours['ours']),\n",
    "            # }\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "            print(gradient)\n",
    "            \n",
    "            subfamresults[env_id]['\\\\saynt (one-by-one)'] += [(min if minimizing else max)([aggregator(np.array(list(saynt[k][2].values())).flatten().tolist()) for k in saynt.keys()])]\n",
    "            subfamresults[env_id]['\\\\saynt (one-by-one)'] += [(min if minimizing else max)([aggregator(np.array(list(saynt[k][2].values())).flatten().tolist()) for k in saynt.keys()])]\n",
    "            subfamresults[env_id]['\\\\saynt (union)'] += [aggregator(union_results['subfamily']) if union_results else np.nan]\n",
    "            subfamresults[env_id]['\\\\ours  (subfamily)'] += [aggregator(ours['ours'])]\n",
    "            \n",
    "            whlfamresults[env_id]['\\\\saynt (one-by-one)'] += [aggregator([item[-1] if item[-1] is not None else np.nan for train, item in saynt.items()])]\n",
    "            whlfamresults[env_id]['\\\\saynt (union)'] += [float(union_results['whole_family']) if union_results else np.nan]\n",
    "            whlfamresults[env_id]['\\\\ours  (subfamily)'] += [float(ours['whole_family'])]\n",
    "            whlfamresults[env_id]['\\\\ours  (whole family)'] += [rfpg_results['gd-normal']['best_worst_value']]\n",
    "            \n",
    "        assert count > 0\n",
    "        print(env, whlfamresults[env_id]['\\\\saynt (one-by-one)'])\n",
    "        subfamresults[env_id]['\\\\saynt (one-by-one)'] = np.median(subfamresults[env_id]['\\\\saynt (one-by-one)'])\n",
    "        subfamresults[env_id]['\\\\saynt (union)']  = np.median(subfamresults[env_id]['\\\\saynt (union)'])\n",
    "        subfamresults[env_id]['\\\\ours  (subfamily)']  = np.median(subfamresults[env_id]['\\\\ours  (subfamily)'])\n",
    "        \n",
    "        whlfamresults[env_id]['\\\\saynt (one-by-one)']  = np.median(hotfix(np.array(whlfamresults[env_id]['\\\\saynt (one-by-one)']))) # TODO this is a hotfix (replace NaN's by value of uniform random value)\n",
    "        whlfamresults[env_id]['\\\\saynt (union)']  = np.median(whlfamresults[env_id]['\\\\saynt (union)'])\n",
    "        whlfamresults[env_id]['\\\\ours  (subfamily)']  = np.median(whlfamresults[env_id]['\\\\ours  (subfamily)'])\n",
    "        whlfamresults[env_id]['\\\\ours  (whole family)'] = np.median(whlfamresults[env_id]['\\\\ours  (whole family)'])\n",
    "        \n",
    "        # subfamresults[env_id] = {\n",
    "        #     # min if minimizing because taking the best FSC out of the 10 FSCs, but worst value for that FSC among the 10 POMDPs evaluated. \n",
    "        #     '\\\\saynt (one-by-one)' : (min if minimizing else max)([aggregator(np.array(list(saynt[k][2].values())).flatten().tolist()) for k in saynt.keys()]),\n",
    "        #     '\\\\saynt (union)' : aggregator(union_results['subfamily']) if union_results else np.nan,\n",
    "        #     '\\\\ours  (subfamily)'  : aggregator(ours['ours']),\n",
    "        # }\n",
    "\n",
    "        # whlfamresults[env_id] = {\n",
    "        #     '\\\\saynt (one-by-one)' : aggregator([item[-1] if item[-1] is not None else np.nan for train, item in saynt.items()]),\n",
    "        #     '\\\\saynt (union)' : float(union_results['whole_family']) if union_results else np.nan,\n",
    "        #     '\\\\ours  (subfamily)'  : float(ours['whole_family']),\n",
    "        #     '\\\\ours  (whole family)' : rfpg_results['gd-normal']['best_worst_value']\n",
    "        # }\n",
    "    \n",
    "    return subfamresults, whlfamresults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfam, whlfam = create_table(ENV_NAMES, MINIMIZING, include_union_results=True)\n",
    "subfam, whlfam = create_table_multiple_seeds(ENV_NAMES, MINIMIZING, include_union_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_highlight() -> str:\n",
    "    return \"highlight:--rwrap;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_latex_str(df : pd.DataFrame):\n",
    "    df = df.round(decimals=2)\n",
    "    return df[:3].style.highlight_max(axis=1, props=pd_highlight().format(precision=2)).concat(df[3:].style.highlight_min(axis=1, props=pd_highlight()).format(precision=2)).format(precision=2).to_latex(hrules=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Whole family results:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(subfam).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(whlfam).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_latex_str(pd.DataFrame(whlfam).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{OUTPUT_DIR}/whlfam.tex\", 'w') as file:\n",
    "    print(to_latex_str(pd.DataFrame(whlfam).T), file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{OUTPUT_DIR}/subfam.tex\", 'w') as file:\n",
    "    print(to_latex_str(pd.DataFrame(subfam).T), file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(subfam).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_latex_str(pd.DataFrame(subfam).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(env : str, plot_gradient_baseline = False, include_union_results = False, **kwargs):\n",
    "    saynt, ours, union_results = load_results(env, include_union_results=include_union_results)\n",
    "\n",
    "    if plot_gradient_baseline:\n",
    "        with open(f\"{BASE_DIR}/{env}/{SUBFAMILY_SIZE}/gradient.pickle\", 'rb') as handle:\n",
    "            gradient = pickle.load(handle)\n",
    "\n",
    "        make_heatmap(gradient, ours, env.upper(), \"GD\", union_results=union_results, **kwargs)\n",
    "\n",
    "    make_heatmap(saynt, ours, env.upper(), \"Saynt\", union_results=union_results, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomdp_families import POMDPFamiliesSynthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_number_of_states(env):\n",
    "    gd = POMDPFamiliesSynthesis(env)\n",
    "    highest_nr_states = 0\n",
    "    for hole_combination in gd.pomdp_sketch.family.all_combinations():\n",
    "        assignment = gd.pomdp_sketch.family.construct_assignment(hole_combination)\n",
    "        pomdp = gd.pomdp_sketch.build_pomdp(assignment)\n",
    "        curr_nr_states = pomdp.model.nr_states\n",
    "        highest_nr_states = max(highest_nr_states, curr_nr_states)\n",
    "    return highest_nr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_and_random_policy_value(env, stratified=True, subfamily_size=SUBFAMILY_SIZE):\n",
    "    gd = POMDPFamiliesSynthesis(env)\n",
    "    family_size = gd.pomdp_sketch.family.size\n",
    "    rand_fsc = gd.random_fsc(1)\n",
    "    \n",
    "    dtmc_sketch = gd.get_dtmc_sketch(rand_fsc)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        if stratified:\n",
    "            subfamily_assigments, hole_combinations = gd.stratified_subfamily_sampling(subfamily_size, seed=seed)\n",
    "        else:\n",
    "            subfamily_assigments, hole_combinations = gd.create_random_subfamily(subfamily_size)\n",
    "    \n",
    "        evaluations = gd.get_values_on_subfamily(dtmc_sketch, subfamily_assigments)\n",
    "        \n",
    "        results[seed] = {\n",
    "            'hole_combinations' : hole_combinations,\n",
    "            'evaluations' : evaluations\n",
    "        }\n",
    "\n",
    "    _, family_value = gd.paynt_call(dtmc_sketch)\n",
    "    \n",
    "    results['family_value'] = family_value\n",
    "    \n",
    "    results['family_size'] = gd.pomdp_sketch.family.size\n",
    "    results['num_actions'] = gd.pomdp_sketch.num_actions\n",
    "    results['num_observations'] = gd.pomdp_sketch.num_observations\n",
    "    \n",
    "    results['max_num_states'] = get_max_number_of_states(env)\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics = {}\n",
    "# for env in ENVS:\n",
    "#     statistics[env] = get_statistics_and_random_policy_value(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./statistics.pickle\", 'wb') as handle:\n",
    "#     pickle.dump(statistics, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env, minimizing in zip(ENV_NAMES, MINIMIZING):\n",
    "    # try:\n",
    "    create_heatmap(env, minimizing=minimizing, include_union_results=False)\n",
    "    # except:\n",
    "        # print(env, 'failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_DIR = f\"{BASE_DIR}/obstacles-illustrative-2/{SUBFAMILY_SIZE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomdp_families import POMDPFamiliesSynthesis\n",
    "from config import ILLUSTRATIVE\n",
    "\n",
    "seed = 11\n",
    "gd = POMDPFamiliesSynthesis(ILLUSTRATIVE, use_softmax=True, steps=1, learning_rate=0.01, seed=seed)\n",
    "subfamily_assigments, hole_combinations = gd.stratified_subfamily_sampling(SUBFAMILY_SIZE, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{EXAMPLE_DIR}/ours-sparse.pickle\", 'rb') as handle:\n",
    "    ours = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsc = ours['fsc']\n",
    "fsc.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.paynt_call_given_fsc(fsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "det_fsc = copy.deepcopy(fsc)\n",
    "for node in range(det_fsc.num_nodes):\n",
    "    for obs in range(det_fsc.num_observations):\n",
    "        det_fsc.action_function[node][obs] = max(fsc.action_function[node][obs], key=fsc.action_function[node][obs].get)        \n",
    "        det_fsc.update_function[node][obs] = max(fsc.update_function[node][obs], key=fsc.update_function[node][obs].get)\n",
    "det_fsc.is_deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_fsc.make_stochastic()\n",
    "gd.paynt_call_given_fsc(det_fsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{EXAMPLE_DIR}/saynt.pickle\", 'rb') as handle:\n",
    "    subfamily_saynt_results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{EXAMPLE_DIR}/paynt.pickle\", 'rb') as handle:\n",
    "    subfamily_paynt_results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{EXAMPLE_DIR}/gradient.pickle\", 'rb') as handle:\n",
    "    subfamily_gd_results = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap(subfamily_paynt_results, ours, \"Illustrative Example\", \"Paynt\", minimizing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap(subfamily_saynt_results, ours, \"Illustrative Example\", \"Saynt\", minimizing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_heatmap(subfamily_gd_results, ours, \"Illustrative Example\", \"GD\", minimizing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env, minimizing in zip(ENV_NAMES, MINIMIZING):\n",
    "    if 'avoid' in env.lower(): continue\n",
    "    values = np.zeros((1, 11))\n",
    "    # print(env)\n",
    "    with open(f\"{BASE_DIR}/{env}/union/union.pickle\", 'rb') as handle:\n",
    "        results = pickle.load(handle)\n",
    "    values[0, :-1] = results['subfamily']\n",
    "    values[0, -1]  = results['whole_family']\n",
    "    \n",
    "    with open(f\"{BASE_DIR}/{env}/{SUBFAMILY_SIZE}/ours.pickle\", 'rb') as handle:\n",
    "        our_results = pickle.load(handle)\n",
    "        \n",
    "    with open(f\"{BASE_DIR}/{env}/gd-experiment.pickle\", 'rb') as handle:\n",
    "        rfpg_results = pickle.load(handle)\n",
    "    \n",
    "    print(rfpg_results['gd-normal'].keys())\n",
    "        \n",
    "    print(env.upper(), f\"MINIMIZING={minimizing}\", results['subfamily'], f\"UNION worst out of subfamily: {max(results['subfamily']) if minimizing else min(results['subfamily'])}\", f\"UNION Whole family worst: {results['whole_family']}\", sep='\\n')\n",
    "    print(our_results['ours'], f\"OURS worst out of subfamily: {max(our_results['ours']) if minimizing else min(our_results['ours'])}\", f\"OURS Whole family worst: {our_results['whole_family']}\", sep='\\n')\n",
    "    print(f\"OURS FULL GD whole family worst: {rfpg_results['gd-normal']['best_worst_value']}\")\n",
    "    \n",
    "\n",
    "    # plt.figure()\n",
    "    # sns.heatmap(values, yticklabels=[env], annot=True, vmin=np.nanmin(values), vmax=np.nanmax(values), cmap=sns.cm.rocket_r if minimizing else sns.cm.rocket, mask=~np.isfinite(values), fmt='.2f')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
